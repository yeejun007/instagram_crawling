{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from scrapy.http import TextResponse\n",
    "import seaborn as sns\n",
    "import getpass\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기서부터 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그인 함수 (seleniun webdriver)\n",
    "\n",
    "def login():\n",
    "    login_url = \"https://www.instagram.com/accounts/login/?source=auth_switcher\"\n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(login_url)\n",
    "    \n",
    "    my_id = input('id를 입력하세요: ')\n",
    "    my_password = getpass.getpass('password를 입력하세요: ')\n",
    "\n",
    "    driver.find_element_by_css_selector('._2hvTZ.pexuQ.zyHYP[type=text]').send_keys(my_id)\n",
    "    driver.find_element_by_css_selector('._2hvTZ.pexuQ.zyHYP[type=password]').send_keys(my_password)\n",
    "    driver.find_element_by_css_selector('.sqdOP.L3NKy.y3zKF[type=submit]').click()\n",
    "    \n",
    "    time.sleep(2.5)\n",
    "    \n",
    "    # 알림설정 하라는 modal창이 뜨는경우 '나중에 하기'를 클릭하는 코드\n",
    "    alert_modal = driver.find_element_by_css_selector('body > div.RnEpo.Yx5HN > div > div')\n",
    "    if alert_modal:\n",
    "        driver.find_element_by_css_selector('body > div.RnEpo.Yx5HN > div > div > div.mt3GC > button.aOOlW.HoLwm').click()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색어를 입력하고 게시물이 가장 많은 검색결과를 클릭 (seleniun webdriver)\n",
    "\n",
    "def crawling_keyword(word):\n",
    "    keyword = word\n",
    "\n",
    "    driver.find_element_by_css_selector('#react-root > section > nav > div._8MQSO.Cx7Bp > div > div > div.LWmhU._0aCwM > input').send_keys(keyword)\n",
    "\n",
    "    # 키워드 입력하고, 키워드에 대한 검색 리스트가 뜨는데 걸리는 시간만큼 기다려준다\n",
    "    time.sleep(1.5)\n",
    "    \n",
    "    search_list = driver.find_elements_by_css_selector('#react-root > section > nav > div._8MQSO.Cx7Bp > div > div > div.LWmhU._0aCwM > div:nth-child(4) > div.drKGC > div > a')\n",
    "    \n",
    "    # 서칭된 a 엘리먼트들 중에 게시물 갯수가 가장 많은 a 엘리먼트를 뽑는다\n",
    "    number_list = []\n",
    "\n",
    "    for element in search_list:\n",
    "        splited_element = element.text.split('게시물')\n",
    "        if len(splited_element) == 2:\n",
    "            number_list.append(int(re.sub(\",\", \"\", splited_element[1])))\n",
    "        else:\n",
    "            number_list.append(0)\n",
    "\n",
    "    max_number = max(number_list)\n",
    "    click_index = number_list.index(max_number)\n",
    "    \n",
    "    # 클릭하고 렌더링이 완료되도록 조금 기다리기\n",
    "    search_list[click_index].click()\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인기게시물 9개는 빼고, 최근사진부터 크롤링 시작(인기게시물과 최근게시물에 중복 게시물이 있을거 같아서)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음 렌더링된 화면의 24개의 게시물을 크롤링하는 함수\n",
    "\n",
    "def initial_crawling():\n",
    "    urls = driver.find_elements_by_xpath(\n",
    "        '//*[@id=\"react-root\"]/section/main/article/div[2]/div/div/div/a')\n",
    "    urls = [url.get_attribute(\"href\") for url in urls]\n",
    "\n",
    "    hash_tag_df = pd.DataFrame(columns=['time', 'hash_tag'])\n",
    "\n",
    "    for i in range(len(urls)):\n",
    "        req = requests.get(urls[i])\n",
    "        response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "        hash_tag_list = response.css(\"meta[property='instapp:hashtags']\")\n",
    "        hash_tag_list = ['#' + hash_tag.attrib['content']\n",
    "                         for hash_tag in hash_tag_list]\n",
    "        hash_tags = ', '.join(hash_tag_list)\n",
    "\n",
    "        data = [\n",
    "            {'time': 0, 'hash_tag': hash_tags}\n",
    "        ]\n",
    "        df = pd.DataFrame(data)\n",
    "        hash_tag_df = hash_tag_df.append(df)\n",
    "\n",
    "    return hash_tag_df.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스크롤내리면서 12개씩 추가되는 게시물을 크롤링하는 함수 (두번째만 실행) - chrome 전체화면 기준\n",
    "# 현재 브라우저 화면 크기에 따라 추가적으로 불러오는 div 갯수가 달라짐\n",
    "# 전체화면 기준 div의 urls 총 갯수 = 24 -> 36 -> 45 -> 45 -> ...\n",
    "\n",
    "def second_crawling():\n",
    "    for i in range(0, 1):\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "        time.sleep(1)\n",
    "\n",
    "        urls = driver.find_elements_by_xpath(\n",
    "            '//*[@id=\"react-root\"]/section/main/article/div[2]/div/div/div/a')\n",
    "        urls = [url.get_attribute(\"href\") for url in urls]\n",
    "\n",
    "        hash_tag_df = pd.DataFrame(columns=['time', 'hash_tag'])\n",
    "\n",
    "        for i in range(len(urls) - 12, len(urls)):\n",
    "            req = requests.get(urls[i])\n",
    "            response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "            hash_tag_list = response.css(\"meta[property='instapp:hashtags']\")\n",
    "            hash_tag_list = ['#' + hash_tag.attrib['content']\n",
    "                             for hash_tag in hash_tag_list]\n",
    "            hash_tags = ', '.join(hash_tag_list)\n",
    "\n",
    "            data = [\n",
    "                {'time': 0, 'hash_tag': hash_tags}\n",
    "            ]\n",
    "            df = pd.DataFrame(data)\n",
    "            hash_tag_df = hash_tag_df.append(df)\n",
    "\n",
    "    return hash_tag_df.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세번째부터는 이 함수 반복하기 - 게시물 9개씩 크롤링\n",
    "\n",
    "def repeat_crawling():\n",
    "    for i in range(0, 1):\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "        time.sleep(1)\n",
    "\n",
    "        urls = driver.find_elements_by_xpath(\n",
    "            '//*[@id=\"react-root\"]/section/main/article/div[2]/div/div/div/a')\n",
    "        urls = [url.get_attribute(\"href\") for url in urls]\n",
    "\n",
    "        hash_tag_df = pd.DataFrame(columns=['time', 'hash_tag'])\n",
    "\n",
    "        for i in range(len(urls) - 9, len(urls)):\n",
    "            req = requests.get(urls[i])\n",
    "            response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "            hash_tag_list = response.css(\"meta[property='instapp:hashtags']\")\n",
    "            hash_tag_list = ['#' + hash_tag.attrib['content']\n",
    "                             for hash_tag in hash_tag_list]\n",
    "            hash_tags = ', '.join(hash_tag_list)\n",
    "\n",
    "            data = [\n",
    "                {'time': 0, 'hash_tag': hash_tags}\n",
    "            ]\n",
    "            df = pd.DataFrame(data)\n",
    "            hash_tag_df = hash_tag_df.append(df)\n",
    "\n",
    "    return hash_tag_df.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile insta_crawling.py\n",
    "# import requests\n",
    "# import pandas as pd\n",
    "# from selenium import webdriver\n",
    "# from scrapy.http import TextResponse\n",
    "# import seaborn as sns\n",
    "# import getpass\n",
    "# import time\n",
    "\n",
    "\n",
    "class instagram_crawling():\n",
    "    \n",
    "    driver = \"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        login_url = \"https://www.instagram.com/accounts/login/?source=auth_switcher\"\n",
    "        self.driver = webdriver.Chrome()\n",
    "        self.driver.get(login_url)\n",
    "    \n",
    "    \n",
    "    # 로그인 함수 (seleniun webdriver)\n",
    "    def login(self):\n",
    "\n",
    "        my_id = input('id를 입력하세요: ')\n",
    "        my_password = getpass.getpass('password를 입력하세요: ')\n",
    "\n",
    "        self.driver.find_element_by_css_selector('._2hvTZ.pexuQ.zyHYP[type=text]').send_keys(my_id)\n",
    "        self.driver.find_element_by_css_selector('._2hvTZ.pexuQ.zyHYP[type=password]').send_keys(my_password)\n",
    "        self.driver.find_element_by_css_selector('.sqdOP.L3NKy.y3zKF[type=submit]').click()\n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    "        # 알림설정 하라는 modal창이 뜨는경우 '나중에 하기'를 클릭하는 코드\n",
    "        alert_modal = self.driver.find_element_by_css_selector('body > div.RnEpo.Yx5HN > div > div')\n",
    "        if alert_modal:\n",
    "            self.driver.find_element_by_css_selector('body > div.RnEpo.Yx5HN > div > div > div.mt3GC > button.aOOlW.HoLwm').click()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 검색어를 입력하고 게시물이 가장 많은 검색결과를 클릭 (seleniun webdriver)\n",
    "    def crawling_keyword(self, word):\n",
    "        keyword = word\n",
    "\n",
    "        self.driver.find_element_by_css_selector('#react-root > section > nav > div._8MQSO.Cx7Bp > div > div > div.LWmhU._0aCwM > input').send_keys(keyword)\n",
    "\n",
    "        # 키워드 입력하고, 키워드에 대한 검색 리스트가 뜨는데 걸리는 시간만큼 기다려준다\n",
    "        time.sleep(1.5)\n",
    "\n",
    "        search_list = self.driver.find_elements_by_css_selector('#react-root > section > nav > div._8MQSO.Cx7Bp > div > div > div.LWmhU._0aCwM > div:nth-child(4) > div.drKGC > div > a')\n",
    "\n",
    "        # 서칭된 a 엘리먼트들 중에 게시물 갯수가 가장 많은 a 엘리먼트를 뽑는다\n",
    "        number_list = []\n",
    "\n",
    "        for element in search_list:\n",
    "            splited_element = element.text.split('게시물')\n",
    "            if len(splited_element) == 2:\n",
    "                number_list.append(int(re.sub(\",\", \"\", splited_element[1])))\n",
    "            else:\n",
    "                number_list.append(0)\n",
    "\n",
    "        max_number = max(number_list)\n",
    "        click_index = number_list.index(max_number)\n",
    "\n",
    "        # 클릭하고 렌더링이 완료되도록 조금 기다리기\n",
    "        search_list[click_index].click()\n",
    "        time.sleep(1.5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 처음 렌더링된 화면의 24개의 게시물을 크롤링하는 함수\n",
    "    def initial_crawling(self):\n",
    "        urls = self.driver.find_elements_by_xpath('//*[@id=\"react-root\"]/section/main/article/div[2]/div/div/div/a')\n",
    "        urls = [url.get_attribute(\"href\") for url in urls]\n",
    "\n",
    "        hash_tag_df = pd.DataFrame(columns=['time', 'hash_tag'])\n",
    "\n",
    "        for i in range(len(urls)):\n",
    "            req = requests.get(urls[i])\n",
    "            response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "            hash_tag_list = response.css(\"meta[property='instapp:hashtags']\")\n",
    "            hash_tag_list = ['#' + hash_tag.attrib['content'] for hash_tag in hash_tag_list]\n",
    "            hash_tags = ', '.join(hash_tag_list)\n",
    "\n",
    "            data = [\n",
    "                {'time': 0, 'hash_tag': hash_tags}\n",
    "            ]\n",
    "            df = pd.DataFrame(data)\n",
    "            hash_tag_df = hash_tag_df.append(df)\n",
    "\n",
    "        return hash_tag_df.reset_index().drop(columns=['index'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 스크롤내리면서 12개씩 추가되는 게시물을 크롤링하는 함수 (두번째만 실행) - chrome 전체화면 기준\n",
    "    # 현재 브라우저 화면 크기에 따라 추가적으로 불러오는 div 갯수가 달라짐\n",
    "    # 전체화면 기준 div의 urls 총 갯수 = 24 -> 36 -> 45 -> 45 -> ...\n",
    "    def second_crawling(self):\n",
    "        for i in range(0, 1):\n",
    "            self.driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "            time.sleep(1.5)\n",
    "\n",
    "            urls = self.driver.find_elements_by_xpath('//*[@id=\"react-root\"]/section/main/article/div[2]/div/div/div/a')\n",
    "            urls = [url.get_attribute(\"href\") for url in urls]\n",
    "\n",
    "            hash_tag_df = pd.DataFrame(columns=['time', 'hash_tag'])\n",
    "\n",
    "            for i in range(len(urls) - 12, len(urls)):\n",
    "                req = requests.get(urls[i])\n",
    "                response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "                hash_tag_list = response.css(\"meta[property='instapp:hashtags']\")\n",
    "                hash_tag_list = ['#' + hash_tag.attrib['content'] for hash_tag in hash_tag_list]\n",
    "                hash_tags = ', '.join(hash_tag_list)\n",
    "\n",
    "                data = [\n",
    "                    {'time': 0, 'hash_tag': hash_tags}\n",
    "                ]\n",
    "                df = pd.DataFrame(data)\n",
    "                hash_tag_df = hash_tag_df.append(df)\n",
    "\n",
    "        return hash_tag_df.reset_index().drop(columns=['index'])\n",
    "\n",
    "\n",
    "\n",
    "    # 세번째부터는 이 함수 반복하기 - 게시물 9개씩 크롤링\n",
    "    def repeat_crawling(self):\n",
    "        for i in range(0, 1):\n",
    "            self.driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "            time.sleep(1.5)\n",
    "\n",
    "            urls = self.driver.find_elements_by_xpath('//*[@id=\"react-root\"]/section/main/article/div[2]/div/div/div/a')\n",
    "            urls = [url.get_attribute(\"href\") for url in urls]\n",
    "\n",
    "            hash_tag_df = pd.DataFrame(columns=['time', 'hash_tag'])\n",
    "\n",
    "            for i in range(len(urls) - 9, len(urls)):\n",
    "                req = requests.get(urls[i])\n",
    "                response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "                hash_tag_list = response.css(\"meta[property='instapp:hashtags']\")\n",
    "                hash_tag_list = ['#' + hash_tag.attrib['content'] for hash_tag in hash_tag_list]\n",
    "                hash_tags = ', '.join(hash_tag_list)\n",
    "\n",
    "                data = [\n",
    "                    {'time': 0, 'hash_tag': hash_tags}\n",
    "                ]\n",
    "                df = pd.DataFrame(data)\n",
    "                hash_tag_df = hash_tag_df.append(df)\n",
    "\n",
    "        return hash_tag_df.reset_index().drop(columns=['index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "insta = instagram_crawling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id를 입력하세요: yeejun90\n",
      "password를 입력하세요: ········\n"
     ]
    }
   ],
   "source": [
    "insta.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "insta.crawling_keyword('초코우유')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>hash_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#당충전, #울산, #제이제이커피, #울산카페, #금요일, #디저트, #수제간식, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>#초코우유, #제주말차, #오레오, #인절미, #라임, #오렌지요거트, #산딸기요거...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>#사이좋은남매, #choco, #비숑, #우다다다, #poodlestagram, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#인친, #like, #instagram, #seoul, #핫플, #홍대, #데일리...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>#펭럽유, #딸기우유, #youus, #펭수, #ebs, #giantpengtv, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>#초코우유</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>#초코아이스크림, #초코우유, #초코바라기, #초코요정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>#김치, #초코우유, #짜파게티</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>#초코우유, #06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>#꽃중독, #내공간, #아이스초코, #초코중독, #집, #제티, #핫초코미떼, #봄...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>#안경나라맞은편, #티라미수, #황치즈, #음성터미널, #마카롱예약, #음성마카롱,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>#취미, #홈카페, #맞팔, #소통, #초코우유, #following, #likef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>#초코우유, #원당카페, #원당늘봄, #인천카페, #검단카페, #마전카페, #당하카...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>#미운, #직장인소확행, #소확행_작지만_확실한_행복🌿🌿, #간식거리, #초코바, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>#오레오케이크, #초코우유, #간식스타그램, #허쉬초콜릿, #초콜릿, #라떼맛집, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>#럽스타그램, #첫줄반사, #첫줄안녕, #초코우유, #좋반환영, #선팔환영, #lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>#온도차, #토이푸들, #세이블푸들, #poodle, #쿨견, #푸숑스타그램, #푸...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>#덴마크초코초코우유, #초코우유, #팝콘, #편의점, #우유, #편스타그램, #세븐...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>#딸기, #초코우유, #요플레, #비요뜨, #바나나, #몰티져스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>#가족, #푸들, #래브라도리트리버, #반려견, #소형견, #대형견, #댕댕이, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>#당충전, #집앞산, #오늘은뭐하고놀까, #이게무슨짓, #초코우유, #가나초코우유,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>#초코우유, #카카오랏, #쪼꼬우유, #달다구리, #애들간식, #카카오밀크, #스페...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>#유어스, #지에스25, #펭럽유, #펭럽유초코, #펭수우유, #초코우유, #gs2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>#초코, #팔로우, #맞팔해요, #엄마_고마워❤️, #선팔, #파스타, #맞팔, #...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time                                           hash_tag\n",
       "0     0  #당충전, #울산, #제이제이커피, #울산카페, #금요일, #디저트, #수제간식, ...\n",
       "1     0  #초코우유, #제주말차, #오레오, #인절미, #라임, #오렌지요거트, #산딸기요거...\n",
       "2     0  #사이좋은남매, #choco, #비숑, #우다다다, #poodlestagram, #...\n",
       "3     0  #인친, #like, #instagram, #seoul, #핫플, #홍대, #데일리...\n",
       "4     0  #펭럽유, #딸기우유, #youus, #펭수, #ebs, #giantpengtv, ...\n",
       "5     0                                              #초코우유\n",
       "6     0                     #초코아이스크림, #초코우유, #초코바라기, #초코요정\n",
       "7     0                                  #김치, #초코우유, #짜파게티\n",
       "8     0                                         #초코우유, #06\n",
       "9     0  #꽃중독, #내공간, #아이스초코, #초코중독, #집, #제티, #핫초코미떼, #봄...\n",
       "10    0  #안경나라맞은편, #티라미수, #황치즈, #음성터미널, #마카롱예약, #음성마카롱,...\n",
       "11    0  #취미, #홈카페, #맞팔, #소통, #초코우유, #following, #likef...\n",
       "12    0  #초코우유, #원당카페, #원당늘봄, #인천카페, #검단카페, #마전카페, #당하카...\n",
       "13    0  #미운, #직장인소확행, #소확행_작지만_확실한_행복🌿🌿, #간식거리, #초코바, ...\n",
       "14    0  #오레오케이크, #초코우유, #간식스타그램, #허쉬초콜릿, #초콜릿, #라떼맛집, ...\n",
       "15    0  #럽스타그램, #첫줄반사, #첫줄안녕, #초코우유, #좋반환영, #선팔환영, #lo...\n",
       "16    0  #온도차, #토이푸들, #세이블푸들, #poodle, #쿨견, #푸숑스타그램, #푸...\n",
       "17    0  #덴마크초코초코우유, #초코우유, #팝콘, #편의점, #우유, #편스타그램, #세븐...\n",
       "18    0                #딸기, #초코우유, #요플레, #비요뜨, #바나나, #몰티져스\n",
       "19    0  #가족, #푸들, #래브라도리트리버, #반려견, #소형견, #대형견, #댕댕이, #...\n",
       "20    0  #당충전, #집앞산, #오늘은뭐하고놀까, #이게무슨짓, #초코우유, #가나초코우유,...\n",
       "21    0  #초코우유, #카카오랏, #쪼꼬우유, #달다구리, #애들간식, #카카오밀크, #스페...\n",
       "22    0  #유어스, #지에스25, #펭럽유, #펭럽유초코, #펭수우유, #초코우유, #gs2...\n",
       "23    0  #초코, #팔로우, #맞팔해요, #엄마_고마워❤️, #선팔, #파스타, #맞팔, #..."
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insta.initial_crawling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>hash_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#졸업사진, #매매종목, #섹스스토리, #문의가능, #점심레스토랑, #선플, #세종...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>#인친환영, #선팔하면맞팔가요, #소통해요, #선팔맞팔, #오늘의간식, #댓글환영,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#탄생화컵, #생일선물, #🍫, #직접만든, #홈카페, #초코우유, #데이지, #홈...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>#꼭, #사랑입니다그램, #중요치않아, #어피치는, #어피치덕후, #중요하다그램, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>#gs25, #초코우유, #펭럽유초코우유, #펭수, #펭럽유초코</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>#리얼쇼콜라, #마카롱꼬끄, #초코우유, #스믈여덟마카롱</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>#다이어트, #좋아요, #selfie, #럽스타그램, #건강스타그램, #다이어트일기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>#파주카페추천, #헤이리마을, #헤이리카페, #일산맘, #캐릭터디자인, #김포카페,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>#불닭떡볶이, #언니와, #내돈으로, #초코우유, #어제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>#🐧, #먹스타, #insta, #초코우유, #우유, #팔로우, #펭수, #펭럽유,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time                                           hash_tag\n",
       "0     0  #졸업사진, #매매종목, #섹스스토리, #문의가능, #점심레스토랑, #선플, #세종...\n",
       "1     0  #인친환영, #선팔하면맞팔가요, #소통해요, #선팔맞팔, #오늘의간식, #댓글환영,...\n",
       "2     0                                                   \n",
       "3     0  #탄생화컵, #생일선물, #🍫, #직접만든, #홈카페, #초코우유, #데이지, #홈...\n",
       "4     0  #꼭, #사랑입니다그램, #중요치않아, #어피치는, #어피치덕후, #중요하다그램, ...\n",
       "5     0                #gs25, #초코우유, #펭럽유초코우유, #펭수, #펭럽유초코\n",
       "6     0                                                   \n",
       "7     0                    #리얼쇼콜라, #마카롱꼬끄, #초코우유, #스믈여덟마카롱\n",
       "8     0  #다이어트, #좋아요, #selfie, #럽스타그램, #건강스타그램, #다이어트일기...\n",
       "9     0  #파주카페추천, #헤이리마을, #헤이리카페, #일산맘, #캐릭터디자인, #김포카페,...\n",
       "10    0                    #불닭떡볶이, #언니와, #내돈으로, #초코우유, #어제\n",
       "11    0  #🐧, #먹스타, #insta, #초코우유, #우유, #팔로우, #펭수, #펭럽유,..."
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insta.second_crawling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>hash_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#미쁜카페, #한옥, #쑥쑥라떼, #제주리얼말차라떼, #병음료, #제주도, #맛있다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>#카페선호하다, #dessert, #에그타르트, #일상, #👊🏻, #롤케이크, #🍫...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>#일상, #좋아하는것도다다름, #아들둘맘, #도너츠, #바나나우유, #두아들맘, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#초코우유, #오레오, #솔티카라멜, #초코파운드케익, #macaron, #콘치즈휘...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>#초코우유, #칼로리바란스, #앤드, #김남길생각</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>#망원동까눌레, #단호박우유, #밀크티맛집, #까눌레, #카페망원정, #생딸기우유,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>#아들몰래먹기, #엄마스트레스해소용, #꿀맛💕, #미안해아들, #초코우유</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>#오레오레오, #누가바, #인절미, #티라미수, #미니마카롱, #순수우유, #머랭쿠...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  time                                           hash_tag\n",
       "0    0  #미쁜카페, #한옥, #쑥쑥라떼, #제주리얼말차라떼, #병음료, #제주도, #맛있다...\n",
       "1    0  #카페선호하다, #dessert, #에그타르트, #일상, #👊🏻, #롤케이크, #🍫...\n",
       "2    0  #일상, #좋아하는것도다다름, #아들둘맘, #도너츠, #바나나우유, #두아들맘, #...\n",
       "3    0  #초코우유, #오레오, #솔티카라멜, #초코파운드케익, #macaron, #콘치즈휘...\n",
       "4    0                        #초코우유, #칼로리바란스, #앤드, #김남길생각\n",
       "5    0  #망원동까눌레, #단호박우유, #밀크티맛집, #까눌레, #카페망원정, #생딸기우유,...\n",
       "6    0           #아들몰래먹기, #엄마스트레스해소용, #꿀맛💕, #미안해아들, #초코우유\n",
       "7    0                                                   \n",
       "8    0  #오레오레오, #누가바, #인절미, #티라미수, #미니마카롱, #순수우유, #머랭쿠..."
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insta.repeat_crawling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 맨처음 화면의 게시물 갯수\n",
    "\n",
    "urls = driver.find_elements_by_xpath('//*[@id=\"react-root\"]/section/main/article/div[2]/div/div/div/a')\n",
    "urls = [url.get_attribute(\"href\") for url in urls]\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스크롤을 한번 끝까지 내렸을때 새로 불러온 게시물을 포함한 전체 게시물 갯수\n",
    "\n",
    "driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "time.sleep(1.5)\n",
    "urls = driver.find_elements_by_xpath('//*[@id=\"react-root\"]/section/main/article/div[2]/div/div/div/a')\n",
    "urls = [url.get_attribute(\"href\") for url in urls]\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.instagram.com/p/B9pxuKenKyG/'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req = requests.get(urls[0])\n",
    "req.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200 https://www.instagram.com/p/B9pxuKenKyG/>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint.pprint(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.xpath('//*[@id=\"react-root\"]/section/main/div/div[1]/article/div[2]/div[1]/ul/div/li/div/div/div[2]/span/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint.pprint(req.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
