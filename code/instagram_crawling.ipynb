{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from scrapy.http import TextResponse\n",
    "import seaborn as sns\n",
    "import getpass\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기서부터 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_url = \"https://www.instagram.com/accounts/login/?source=auth_switcher\"\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(login_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그인 함수 (seleniun webdriver)\n",
    "\n",
    "def login():\n",
    "#     login_url = \"https://www.instagram.com/accounts/login/?source=auth_switcher\"\n",
    "\n",
    "#     driver = webdriver.Chrome()\n",
    "#     driver.get(login_url)\n",
    "    \n",
    "    my_id = input('id를 입력하세요: ')\n",
    "    my_password = getpass.getpass('password를 입력하세요: ')\n",
    "\n",
    "    driver.find_element_by_css_selector('._2hvTZ.pexuQ.zyHYP[type=text]').send_keys(my_id)\n",
    "    driver.find_element_by_css_selector('._2hvTZ.pexuQ.zyHYP[type=password]').send_keys(my_password)\n",
    "    driver.find_element_by_css_selector('.sqdOP.L3NKy.y3zKF[type=submit]').click()\n",
    "    \n",
    "    time.sleep(2.5)\n",
    "    \n",
    "    # 알림설정 하라는 modal창이 뜨는경우 '나중에 하기'를 클릭하는 코드\n",
    "    alert_modal = driver.find_element_by_css_selector('body > div.RnEpo.Yx5HN > div > div')\n",
    "    if alert_modal:\n",
    "        driver.find_element_by_css_selector('body > div.RnEpo.Yx5HN > div > div > div.mt3GC > button.aOOlW.HoLwm').click()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색어를 입력하고 게시물이 가장 많은 검색결과를 클릭 (seleniun webdriver)\n",
    "\n",
    "def crawling_keyword(word):\n",
    "    keyword = word\n",
    "\n",
    "    driver.find_element_by_css_selector('#react-root > section > nav > div._8MQSO.Cx7Bp > div > div > div.LWmhU._0aCwM > input').send_keys(keyword)\n",
    "\n",
    "    # 키워드 입력하고, 키워드에 대한 검색 리스트가 뜨는데 걸리는 시간만큼 기다려준다\n",
    "    time.sleep(1.5)\n",
    "    \n",
    "    search_list = driver.find_elements_by_css_selector('#react-root > section > nav > div._8MQSO.Cx7Bp > div > div > div.LWmhU._0aCwM > div:nth-child(4) > div.drKGC > div > a')\n",
    "    \n",
    "    # 서칭된 a 엘리먼트들 중에 게시물 갯수가 가장 많은 a 엘리먼트를 뽑는다\n",
    "    number_list = []\n",
    "\n",
    "    for element in search_list:\n",
    "        splited_element = element.text.split('게시물')\n",
    "        if len(splited_element) == 2:\n",
    "            number_list.append(int(re.sub(\",\", \"\", splited_element[1])))\n",
    "        else:\n",
    "            number_list.append(0)\n",
    "\n",
    "    max_number = max(number_list)\n",
    "    click_index = number_list.index(max_number)\n",
    "    \n",
    "    # 클릭하고 렌더링이 완료되도록 조금 기다리기\n",
    "    search_list[click_index].click()\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인기게시물 9개는 빼고, 최근사진부터 크롤링 시작(인기게시물과 최근게시물에 중복 게시물이 있을거 같아서)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음 렌더링된 화면의 24개의 게시물을 크롤링하는 함수\n",
    "\n",
    "def initial_crawling():\n",
    "    urls = driver.find_elements_by_xpath(\n",
    "        '//*[@id=\"react-root\"]/section/main/article/div[2]/div/div/div/a')\n",
    "    urls = [url.get_attribute(\"href\") for url in urls]\n",
    "\n",
    "    hash_tag_df = pd.DataFrame(columns=['time', 'hash_tag'])\n",
    "\n",
    "    for i in range(len(urls)):\n",
    "        req = requests.get(urls[i])\n",
    "        response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "        hash_tag_list = response.css(\"meta[property='instapp:hashtags']\")\n",
    "        hash_tag_list = ['#' + hash_tag.attrib['content']\n",
    "                         for hash_tag in hash_tag_list]\n",
    "        hash_tags = ', '.join(hash_tag_list)\n",
    "\n",
    "        data = [\n",
    "            {'time': 0, 'hash_tag': hash_tags}\n",
    "        ]\n",
    "        df = pd.DataFrame(data)\n",
    "        hash_tag_df = hash_tag_df.append(df)\n",
    "\n",
    "    return hash_tag_df.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스크롤내리면서 12개씩 추가되는 게시물을 크롤링하는 함수 (두번째만 실행) - chrome 전체화면 기준\n",
    "# 현재 브라우저 화면 크기에 따라 추가적으로 불러오는 div 갯수가 달라짐\n",
    "# 전체화면 기준 div의 urls 총 갯수 = 24 -> 36 -> 45 -> 45 -> ...\n",
    "\n",
    "def second_crawling():\n",
    "    \n",
    "    hash_tag_df = pd.DataFrame(columns=['time', 'hash_tag'])\n",
    "    \n",
    "    for i in range(0, 1):\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "        time.sleep(1)\n",
    "\n",
    "        urls = driver.find_elements_by_xpath('//*[@id=\"react-root\"]/section/main/article/div[2]/div/div/div/a')\n",
    "        urls = [url.get_attribute(\"href\") for url in urls]\n",
    "\n",
    "        for i in range(len(urls) - 12, len(urls)):\n",
    "            req = requests.get(urls[i])\n",
    "            response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "            hash_tag_list = response.css(\"meta[property='instapp:hashtags']\")\n",
    "            hash_tag_list = ['#' + hash_tag.attrib['content']\n",
    "                             for hash_tag in hash_tag_list]\n",
    "            hash_tags = ', '.join(hash_tag_list)\n",
    "\n",
    "            data = [\n",
    "                {'time': 0, 'hash_tag': hash_tags}\n",
    "            ]\n",
    "            df = pd.DataFrame(data)\n",
    "            hash_tag_df = hash_tag_df.append(df)\n",
    "\n",
    "    return hash_tag_df.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세번째부터는 이 함수 반복하기 -  게시물 9개씩 크롤링\n",
    "\n",
    "def repeat_crawling(num):\n",
    "    \n",
    "    hash_tag_df = pd.DataFrame(columns=['time', 'hash_tag'])\n",
    "    \n",
    "    for i in range(0, num):\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "        time.sleep(1)\n",
    "\n",
    "        urls = driver.find_elements_by_xpath('//*[@id=\"react-root\"]/section/main/article/div[2]/div/div/div/a')\n",
    "        urls = [url.get_attribute(\"href\") for url in urls]\n",
    "\n",
    "        for i in range(len(urls) - 9, len(urls)):\n",
    "            req = requests.get(urls[i])\n",
    "            response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "            hash_tag_list = response.css(\"meta[property='instapp:hashtags']\")\n",
    "            hash_tag_list = ['#' + hash_tag.attrib['content']\n",
    "                             for hash_tag in hash_tag_list]\n",
    "            hash_tags = ', '.join(hash_tag_list)\n",
    "\n",
    "            data = [\n",
    "                {'time': 0, 'hash_tag': hash_tags}\n",
    "            ]\n",
    "            df = pd.DataFrame(data)\n",
    "            hash_tag_df = hash_tag_df.append(df)\n",
    "\n",
    "    return hash_tag_df.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile insta_crawling.py\n",
    "# import requests\n",
    "# import pandas as pd\n",
    "# from selenium import webdriver\n",
    "# from scrapy.http import TextResponse\n",
    "# import seaborn as sns\n",
    "# import getpass\n",
    "# import time\n",
    "\n",
    "\n",
    "class instagram_crawling():\n",
    "    \n",
    "    driver = \"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        login_url = \"https://www.instagram.com/accounts/login/?source=auth_switcher\"\n",
    "        self.driver = webdriver.Chrome()\n",
    "        self.driver.get(login_url)\n",
    "    \n",
    "    \n",
    "    # 로그인 함수 (seleniun webdriver)\n",
    "    def login(self):\n",
    "\n",
    "        my_id = input('id를 입력하세요: ')\n",
    "        my_password = getpass.getpass('password를 입력하세요: ')\n",
    "\n",
    "        self.driver.find_element_by_css_selector('._2hvTZ.pexuQ.zyHYP[type=text]').send_keys(my_id)\n",
    "        self.driver.find_element_by_css_selector('._2hvTZ.pexuQ.zyHYP[type=password]').send_keys(my_password)\n",
    "        self.driver.find_element_by_css_selector('.sqdOP.L3NKy.y3zKF[type=submit]').click()\n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    "        # 알림설정 하라는 modal창이 뜨는경우 '나중에 하기'를 클릭하는 코드\n",
    "        alert_modal = self.driver.find_element_by_css_selector('body > div.RnEpo.Yx5HN > div > div')\n",
    "        if alert_modal:\n",
    "            self.driver.find_element_by_css_selector('body > div.RnEpo.Yx5HN > div > div > div.mt3GC > button.aOOlW.HoLwm').click()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 검색어를 입력하고 게시물이 가장 많은 검색결과를 클릭 (seleniun webdriver)\n",
    "    def crawling_keyword(self, word):\n",
    "        keyword = word\n",
    "\n",
    "        self.driver.find_element_by_css_selector('#react-root > section > nav > div._8MQSO.Cx7Bp > div > div > div.LWmhU._0aCwM > input').send_keys(keyword)\n",
    "\n",
    "        # 키워드 입력하고, 키워드에 대한 검색 리스트가 뜨는데 걸리는 시간만큼 기다려준다\n",
    "        time.sleep(1.5)\n",
    "\n",
    "        search_list = self.driver.find_elements_by_css_selector('#react-root > section > nav > div._8MQSO.Cx7Bp > div > div > div.LWmhU._0aCwM > div:nth-child(4) > div.drKGC > div > a')\n",
    "\n",
    "        # 서칭된 a 엘리먼트들 중에 게시물 갯수가 가장 많은 a 엘리먼트를 뽑는다\n",
    "        number_list = []\n",
    "\n",
    "        for element in search_list:\n",
    "            splited_element = element.text.split('게시물')\n",
    "            if len(splited_element) == 2:\n",
    "                number_list.append(int(re.sub(\",\", \"\", splited_element[1])))\n",
    "            else:\n",
    "                number_list.append(0)\n",
    "\n",
    "        max_number = max(number_list)\n",
    "        click_index = number_list.index(max_number)\n",
    "\n",
    "        # 클릭하고 렌더링이 완료되도록 조금 기다리기\n",
    "        search_list[click_index].click()\n",
    "        time.sleep(1.5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 처음 렌더링된 화면의 24개의 게시물을 크롤링하는 함수\n",
    "    def initial_crawling(self):\n",
    "        urls = self.driver.find_elements_by_xpath('//*[@id=\"react-root\"]/section/main/article/div[2]/div/div/div/a')\n",
    "        urls = [url.get_attribute(\"href\") for url in urls]\n",
    "\n",
    "        hash_tag_df = pd.DataFrame(columns=['time', 'hash_tag'])\n",
    "\n",
    "        for i in range(len(urls)):\n",
    "            req = requests.get(urls[i])\n",
    "            response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "            hash_tag_list = response.css(\"meta[property='instapp:hashtags']\")\n",
    "            hash_tag_list = ['#' + hash_tag.attrib['content'] for hash_tag in hash_tag_list]\n",
    "            hash_tags = ', '.join(hash_tag_list)\n",
    "\n",
    "            data = [\n",
    "                {'time': 0, 'hash_tag': hash_tags}\n",
    "            ]\n",
    "            df = pd.DataFrame(data)\n",
    "            hash_tag_df = hash_tag_df.append(df)\n",
    "\n",
    "        return hash_tag_df.reset_index().drop(columns=['index'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 스크롤내리면서 12개씩 추가되는 게시물을 크롤링하는 함수 (두번째만 실행) - chrome 전체화면 기준\n",
    "    # 현재 브라우저 화면 크기에 따라 추가적으로 불러오는 div 갯수가 달라짐\n",
    "    # 전체화면 기준 div의 urls 총 갯수 = 24 -> 36 -> 45 -> 45 -> ...\n",
    "    def second_crawling(self):\n",
    "        \n",
    "        hash_tag_df = pd.DataFrame(columns=['time', 'hash_tag'])\n",
    "        \n",
    "        for i in range(0, 1):\n",
    "            self.driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "            time.sleep(1.5)\n",
    "\n",
    "            urls = self.driver.find_elements_by_xpath('//*[@id=\"react-root\"]/section/main/article/div[2]/div/div/div/a')\n",
    "            urls = [url.get_attribute(\"href\") for url in urls]\n",
    "\n",
    "            for i in range(len(urls) - 12, len(urls)):\n",
    "                req = requests.get(urls[i])\n",
    "                response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "                hash_tag_list = response.css(\"meta[property='instapp:hashtags']\")\n",
    "                hash_tag_list = ['#' + hash_tag.attrib['content'] for hash_tag in hash_tag_list]\n",
    "                hash_tags = ', '.join(hash_tag_list)\n",
    "\n",
    "                data = [\n",
    "                    {'time': 0, 'hash_tag': hash_tags}\n",
    "                ]\n",
    "                df = pd.DataFrame(data)\n",
    "                hash_tag_df = hash_tag_df.append(df)\n",
    "\n",
    "        return hash_tag_df.reset_index().drop(columns=['index'])\n",
    "\n",
    "\n",
    "\n",
    "    # 세번째부터는 이 함수 반복하기 - 게시물 9개씩 크롤링\n",
    "    def repeat_crawling(self, num):\n",
    "        \n",
    "        hash_tag_df = pd.DataFrame(columns=['time', 'hash_tag'])\n",
    "        \n",
    "        for i in range(0, num):\n",
    "            try:\n",
    "                self.driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "                time.sleep(1.5)\n",
    "\n",
    "                urls = self.driver.find_elements_by_xpath('//*[@id=\"react-root\"]/section/main/article/div[2]/div/div/div/a')\n",
    "                urls = [url.get_attribute(\"href\") for url in urls]\n",
    "\n",
    "                for i in range(len(urls) - 9, len(urls)):\n",
    "                    req = requests.get(urls[i])\n",
    "                    response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "                    hash_tag_list = response.css(\"meta[property='instapp:hashtags']\")\n",
    "                    hash_tag_list = ['#' + hash_tag.attrib['content'] for hash_tag in hash_tag_list]\n",
    "                    hash_tags = ', '.join(hash_tag_list)\n",
    "\n",
    "                    data = [\n",
    "                        {'time': 0, 'hash_tag': hash_tags}\n",
    "                    ]\n",
    "                    df = pd.DataFrame(data)\n",
    "                    hash_tag_df = hash_tag_df.append(df)\n",
    "                    \n",
    "            except Exception as exc:\n",
    "                print('에러가 발생했습니다 : ', exc)\n",
    "\n",
    "        return hash_tag_df.reset_index().drop(columns=['index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "insta = instagram_crawling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id를 입력하세요: yeejun90\n",
      "password를 입력하세요: ········\n"
     ]
    }
   ],
   "source": [
    "insta.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "insta.crawling_keyword('초코우유')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>hash_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#달콤, #소풍스타그램, #티라미수, #핵잼, #초코우유, #홍차, #홍대카페, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>#소통, #카페투어, #답례품, #코로나저리가, #수제간식, #행사간식, #구움과자...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>#망고우유, #산딸기요거트, #얼그레이, #오레오, #인절미, #라임, #초코우유,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#푸들, #dogstagram, #비숑프리제, #dogs, #비숑스타그램, #심장뿌...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>#카페, #ootd, #일상, #인친, #좋반, #like, #팔로워, #데일리, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>#감성, #dm, #선팔하면맞팔, #셀카, #초코우유, #분위기, #네일매니저, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>#펭수, #ebs, #펭카, #자이언트펭티비, #펭럽유, #giantpengtv, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>#초코우유</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>#초코바라기, #초코아이스크림, #초코요정, #초코우유</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>#초코우유, #김치, #짜파게티</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>#06, #초코우유</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>#초코중독, #꽃중독, #초코우유, #핫초코미떼, #집, #제티, #꽃, #봄맞이,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>#음성읍, #솔티바닐라, #쩡스마카롱, #꼬끄후레이크, #달코미흑당_, #마카롱배달...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>#following, #취미, #선물, #likeforlikes, #초코우유, #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>#검단카페, #늘봄, #초코우유, #원당늘봄, #원당카페, #카페, #달달구리, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>#헿, #소확행_작지만_확실한_행복🌿🌿, #13일밤의금요일, #직장인소확행, #미운...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>#초콜릿, #카페라떼, #오레오케이크, #라떼맛집, #초코우유, #쿠키앤크림, #허...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>#첫줄반사, #첫줄안녕, #좋반환영, #daily, #fffff, #고1, #푸드스...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>#쿨견, #온도차, #poodle, #남매, #bichonfrise, #토이푸들, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>#덴마크초코초코우유, #버터맛팝콘, #편의점음식, #사조팝콘, #먹스타그램, #세븐...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>#바나나, #몰티져스, #비요뜨, #딸기, #초코우유, #요플레</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>#소형견, #강아지, #반려견, #가족, #푸들, #대형견, #래브라도리트리버, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>#토끼산, #매봉산, #산에다모였나, #지긋지긋한, #오늘은뭐하고놀까, #내일은뭐하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>#줌스타그램, #카카오밀크, #초코우유, #애들간식, #스페인국민음료, #주부놀이,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time                                           hash_tag\n",
       "0     0  #달콤, #소풍스타그램, #티라미수, #핵잼, #초코우유, #홍차, #홍대카페, #...\n",
       "1     0  #소통, #카페투어, #답례품, #코로나저리가, #수제간식, #행사간식, #구움과자...\n",
       "2     0  #망고우유, #산딸기요거트, #얼그레이, #오레오, #인절미, #라임, #초코우유,...\n",
       "3     0  #푸들, #dogstagram, #비숑프리제, #dogs, #비숑스타그램, #심장뿌...\n",
       "4     0  #카페, #ootd, #일상, #인친, #좋반, #like, #팔로워, #데일리, ...\n",
       "5     0  #감성, #dm, #선팔하면맞팔, #셀카, #초코우유, #분위기, #네일매니저, #...\n",
       "6     0  #펭수, #ebs, #펭카, #자이언트펭티비, #펭럽유, #giantpengtv, ...\n",
       "7     0                                              #초코우유\n",
       "8     0                     #초코바라기, #초코아이스크림, #초코요정, #초코우유\n",
       "9     0                                  #초코우유, #김치, #짜파게티\n",
       "10    0                                         #06, #초코우유\n",
       "11    0  #초코중독, #꽃중독, #초코우유, #핫초코미떼, #집, #제티, #꽃, #봄맞이,...\n",
       "12    0  #음성읍, #솔티바닐라, #쩡스마카롱, #꼬끄후레이크, #달코미흑당_, #마카롱배달...\n",
       "13    0  #following, #취미, #선물, #likeforlikes, #초코우유, #2...\n",
       "14    0  #검단카페, #늘봄, #초코우유, #원당늘봄, #원당카페, #카페, #달달구리, #...\n",
       "15    0  #헿, #소확행_작지만_확실한_행복🌿🌿, #13일밤의금요일, #직장인소확행, #미운...\n",
       "16    0  #초콜릿, #카페라떼, #오레오케이크, #라떼맛집, #초코우유, #쿠키앤크림, #허...\n",
       "17    0  #첫줄반사, #첫줄안녕, #좋반환영, #daily, #fffff, #고1, #푸드스...\n",
       "18    0  #쿨견, #온도차, #poodle, #남매, #bichonfrise, #토이푸들, ...\n",
       "19    0  #덴마크초코초코우유, #버터맛팝콘, #편의점음식, #사조팝콘, #먹스타그램, #세븐...\n",
       "20    0                #바나나, #몰티져스, #비요뜨, #딸기, #초코우유, #요플레\n",
       "21    0  #소형견, #강아지, #반려견, #가족, #푸들, #대형견, #래브라도리트리버, #...\n",
       "22    0  #토끼산, #매봉산, #산에다모였나, #지긋지긋한, #오늘은뭐하고놀까, #내일은뭐하...\n",
       "23    0  #줌스타그램, #카카오밀크, #초코우유, #애들간식, #스페인국민음료, #주부놀이,..."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insta.initial_crawling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>hash_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#저녁식사, #유어스, #참깨라면, #지에스25, #펭럽유초코, #음식스타그램, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>#팔로우, #까르보나라, #선팔, #likeforlikeback, #좋반, #맞팔해...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>#여신파마, #가천여행, #선플, #세종카페, #스위스여행, #뮤비촬영, #초코우유...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#일상, #일상그램, #f4, #댓글, #오늘의간식, #선팔맞팔, #소통환영, #일...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>#생일, #탄생화컵, #직접만든, #홈카페놀이, #🍫, #홈카페, #초코우유, #생...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>#꼭, #초코우유, #어피치덕후, #사탕은, #그게, #행복하다그램, #어피치는, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>#펭럽유초코, #펭럽유초코우유, #펭수, #초코우유, #gs25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>#마카롱꼬끄, #스믈여덟마카롱, #초코우유, #리얼쇼콜라</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>#셀피, #chocolate, #좋아요, #당보충, #셀카, #일상스타그램, #식단...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>#보틀우유맛집, #보틀우유, #초코우유, #파주카페, #일산맘, #파주카페추천, #...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time                                           hash_tag\n",
       "0     0  #저녁식사, #유어스, #참깨라면, #지에스25, #펭럽유초코, #음식스타그램, #...\n",
       "1     0  #팔로우, #까르보나라, #선팔, #likeforlikeback, #좋반, #맞팔해...\n",
       "2     0  #여신파마, #가천여행, #선플, #세종카페, #스위스여행, #뮤비촬영, #초코우유...\n",
       "3     0  #일상, #일상그램, #f4, #댓글, #오늘의간식, #선팔맞팔, #소통환영, #일...\n",
       "4     0                                                   \n",
       "5     0  #생일, #탄생화컵, #직접만든, #홈카페놀이, #🍫, #홈카페, #초코우유, #생...\n",
       "6     0  #꼭, #초코우유, #어피치덕후, #사탕은, #그게, #행복하다그램, #어피치는, ...\n",
       "7     0                #펭럽유초코, #펭럽유초코우유, #펭수, #초코우유, #gs25\n",
       "8     0                                                   \n",
       "9     0                    #마카롱꼬끄, #스믈여덟마카롱, #초코우유, #리얼쇼콜라\n",
       "10    0  #셀피, #chocolate, #좋아요, #당보충, #셀카, #일상스타그램, #식단...\n",
       "11    0  #보틀우유맛집, #보틀우유, #초코우유, #파주카페, #일산맘, #파주카페추천, #..."
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insta.second_crawling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>hash_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>#사장님과토크ㅋ, #역시, #코스가, #인, #초코우유, #옴마, #저번에, #레몬...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>#카페, #한옥, #제주리얼말차라떼, #맛있다, #다음기회에👋, #소금앙버터, #미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#초코우유, #쌍문동마카롱, #달달, #일상, #선물, #macarons, #코로나...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>#방학중, #도너츠, #초코우유, #아들둘맘, #좋아하는것도다다름, #아들맘, #바...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>#macaron, #오레오, #화이트데이, #충장로, #까페모카, #말차가나슈, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>#초코우유, #김남길생각, #앤드, #칼로리바란스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>#수제우유, #망원동, #까눌레맛집, #단호박우유, #보틀우유, #카페망원정, #쑥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>#초코우유, #아들몰래먹기, #미안해아들, #꿀맛💕, #엄마스트레스해소용</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>#주부9단, #오리훈제, #닭띠아기, #연근조림, #다둥이맘, #아기식단, #세딸맘...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>#뚱카롱, #오늘의마카롱, #블루베리요거트❌, #딸기우유❌, #제주여행코스, #티라...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>#엄마는외계인, #인절미, #코로나야물러가라, #블루베리요거트, #딸기요거트, #앙...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>#떡볶이, #점심메뉴, #마스크, #초코우유</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>#제주말차, #돼지바, #초코퍼지, #패션후르츠, #소금바닐라, #말차갸또, #얼그...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>#흰우유, #daily, #펭럽유, #펭수앓이, #왕귀엽, #엣헴엣헴신이나, #펭수...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>#미안해서, #언제쯤끝날까, #엄마가미안해, #오늘은뭐하고놀지, #쿠팡없인못살아, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>#파리바게트, #감사히잘먹겠습니다🙏, #출근스타그램, #직장, #초코우유, #간식,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>#흰우유, #초코우유, #20200311, #공복, #펭럽유, #펭클럽, #출근길,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>#바나나우유, #유당프리, #매일유업, #유당분해우유, #매일우유, #소화가잘되는우...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>#불쌍한우리아이들, #채원이, #마스크쓰기좋아하는이채워니, #초코우유, #힘내자, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>#편의점, #20200311, #친구, #1차, #딸기샌드위치, #2차, #초콜릿,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>#20200307, #생후457일, #길해빈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>#초코우유, #연차데이, #꿀연차, #고커피로스터스, #연잎핫도그, #이거먹을라고연...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>#abc주스, #칼로바이, #만보달성👣, #스트레칭하기, #필라테스, #마이다노베이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>#좋아요, #기분좋아, #남사친, #00년생, #코인노래방, #데일리, #닭꼬치, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>#반려견, #초코우유, #래브라도리트리버, #평생, #우유, #푸들, #초코</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time                                           hash_tag\n",
       "0     0                                                   \n",
       "1     0  #사장님과토크ㅋ, #역시, #코스가, #인, #초코우유, #옴마, #저번에, #레몬...\n",
       "2     0  #카페, #한옥, #제주리얼말차라떼, #맛있다, #다음기회에👋, #소금앙버터, #미...\n",
       "3     0  #초코우유, #쌍문동마카롱, #달달, #일상, #선물, #macarons, #코로나...\n",
       "4     0  #방학중, #도너츠, #초코우유, #아들둘맘, #좋아하는것도다다름, #아들맘, #바...\n",
       "5     0  #macaron, #오레오, #화이트데이, #충장로, #까페모카, #말차가나슈, #...\n",
       "6     0                        #초코우유, #김남길생각, #앤드, #칼로리바란스\n",
       "7     0  #수제우유, #망원동, #까눌레맛집, #단호박우유, #보틀우유, #카페망원정, #쑥...\n",
       "8     0           #초코우유, #아들몰래먹기, #미안해아들, #꿀맛💕, #엄마스트레스해소용\n",
       "9     0                                                   \n",
       "10    0  #주부9단, #오리훈제, #닭띠아기, #연근조림, #다둥이맘, #아기식단, #세딸맘...\n",
       "11    0  #뚱카롱, #오늘의마카롱, #블루베리요거트❌, #딸기우유❌, #제주여행코스, #티라...\n",
       "12    0  #엄마는외계인, #인절미, #코로나야물러가라, #블루베리요거트, #딸기요거트, #앙...\n",
       "13    0                           #떡볶이, #점심메뉴, #마스크, #초코우유\n",
       "14    0  #제주말차, #돼지바, #초코퍼지, #패션후르츠, #소금바닐라, #말차갸또, #얼그...\n",
       "15    0  #흰우유, #daily, #펭럽유, #펭수앓이, #왕귀엽, #엣헴엣헴신이나, #펭수...\n",
       "16    0  #미안해서, #언제쯤끝날까, #엄마가미안해, #오늘은뭐하고놀지, #쿠팡없인못살아, ...\n",
       "17    0  #파리바게트, #감사히잘먹겠습니다🙏, #출근스타그램, #직장, #초코우유, #간식,...\n",
       "18    0  #흰우유, #초코우유, #20200311, #공복, #펭럽유, #펭클럽, #출근길,...\n",
       "19    0  #바나나우유, #유당프리, #매일유업, #유당분해우유, #매일우유, #소화가잘되는우...\n",
       "20    0  #불쌍한우리아이들, #채원이, #마스크쓰기좋아하는이채워니, #초코우유, #힘내자, ...\n",
       "21    0  #편의점, #20200311, #친구, #1차, #딸기샌드위치, #2차, #초콜릿,...\n",
       "22    0                           #20200307, #생후457일, #길해빈\n",
       "23    0  #초코우유, #연차데이, #꿀연차, #고커피로스터스, #연잎핫도그, #이거먹을라고연...\n",
       "24    0  #abc주스, #칼로바이, #만보달성👣, #스트레칭하기, #필라테스, #마이다노베이...\n",
       "25    0  #좋아요, #기분좋아, #남사친, #00년생, #코인노래방, #데일리, #닭꼬치, ...\n",
       "26    0         #반려견, #초코우유, #래브라도리트리버, #평생, #우유, #푸들, #초코"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insta.repeat_crawling(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 맨처음 화면의 게시물 갯수\n",
    "\n",
    "urls = driver.find_elements_by_xpath('//*[@id=\"react-root\"]/section/main/article/div[2]/div/div/div/a')\n",
    "urls = [url.get_attribute(\"href\") for url in urls]\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스크롤을 한번 끝까지 내렸을때 새로 불러온 게시물을 포함한 전체 게시물 갯수\n",
    "\n",
    "driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "time.sleep(1.5)\n",
    "urls = driver.find_elements_by_xpath('//*[@id=\"react-root\"]/section/main/article/div[2]/div/div/div/a')\n",
    "urls = [url.get_attribute(\"href\") for url in urls]\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.instagram.com/p/B9pxuKenKyG/'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req = requests.get(urls[0])\n",
    "req.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200 https://www.instagram.com/p/B9pxuKenKyG/>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint.pprint(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.xpath('//*[@id=\"react-root\"]/section/main/div/div[1]/article/div[2]/div[1]/ul/div/li/div/div/div[2]/span/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint.pprint(req.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
