{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from selenium import webdriver\n",
    "from scrapy.http import TextResponse\n",
    "import seaborn as sns\n",
    "import getpass\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë“ˆí™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile insta_crawling.py\n",
    "# import requests\n",
    "# import pymongo\n",
    "# import pandas as pd\n",
    "# from selenium import webdriver\n",
    "# from scrapy.http import TextResponse\n",
    "# import getpass\n",
    "# import time\n",
    "\n",
    "\n",
    "class instagram_crawling():\n",
    "    \n",
    "    driver = \"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        login_url = \"https://www.instagram.com/accounts/login/?source=auth_switcher\"\n",
    "        self.driver = webdriver.Chrome()\n",
    "        self.driver.get(login_url)\n",
    "    \n",
    "    \n",
    "    # ë¡œê·¸ì¸ í•¨ìˆ˜ (seleniun webdriver)\n",
    "    def login(self):\n",
    "\n",
    "        my_id = input('idë¥¼ ì…ë ¥í•˜ì„¸ìš”: ')\n",
    "        my_password = getpass.getpass('passwordë¥¼ ì…ë ¥í•˜ì„¸ìš”: ')\n",
    "\n",
    "        self.driver.find_element_by_css_selector('._2hvTZ.pexuQ.zyHYP[type=text]').send_keys(my_id)\n",
    "        self.driver.find_element_by_css_selector('._2hvTZ.pexuQ.zyHYP[type=password]').send_keys(my_password)\n",
    "        self.driver.find_element_by_css_selector('.sqdOP.L3NKy.y3zKF[type=submit]').click()\n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    "        # ì•Œë¦¼ì„¤ì • í•˜ë¼ëŠ” modalì°½ì´ ëœ¨ëŠ”ê²½ìš° 'ë‚˜ì¤‘ì— í•˜ê¸°'ë¥¼ í´ë¦­í•˜ëŠ” ì½”ë“œ\n",
    "        alert_modal = self.driver.find_element_by_css_selector('body > div.RnEpo.Yx5HN > div > div')\n",
    "        if alert_modal:\n",
    "            self.driver.find_element_by_css_selector('body > div.RnEpo.Yx5HN > div > div > div.mt3GC > button.aOOlW.HoLwm').click()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ê³  ê²Œì‹œë¬¼ì´ ê°€ì¥ ë§ì€ ê²€ìƒ‰ê²°ê³¼ë¥¼ í´ë¦­ (seleniun webdriver)\n",
    "    def crawling_keyword(self, word):\n",
    "        keyword = word\n",
    "\n",
    "        self.driver.find_element_by_css_selector('#react-root > section > nav > div._8MQSO.Cx7Bp > div > div > div.LWmhU._0aCwM > input').send_keys(keyword)\n",
    "\n",
    "        # í‚¤ì›Œë“œ ì…ë ¥í•˜ê³ , í‚¤ì›Œë“œì— ëŒ€í•œ ê²€ìƒ‰ ë¦¬ìŠ¤íŠ¸ê°€ ëœ¨ëŠ”ë° ê±¸ë¦¬ëŠ” ì‹œê°„ë§Œí¼ ê¸°ë‹¤ë ¤ì¤€ë‹¤\n",
    "        time.sleep(1.5)\n",
    "\n",
    "        search_list = self.driver.find_elements_by_css_selector('#react-root > section > nav > div._8MQSO.Cx7Bp > div > div > div.LWmhU._0aCwM > div:nth-child(4) > div.drKGC > div > a')\n",
    "\n",
    "        # ì„œì¹­ëœ a ì—˜ë¦¬ë¨¼íŠ¸ë“¤ ì¤‘ì— ê²Œì‹œë¬¼ ê°¯ìˆ˜ê°€ ê°€ì¥ ë§ì€ a ì—˜ë¦¬ë¨¼íŠ¸ë¥¼ ë½‘ëŠ”ë‹¤\n",
    "        number_list = []\n",
    "\n",
    "        for element in search_list:\n",
    "            splited_element = element.text.split('ê²Œì‹œë¬¼')\n",
    "            if len(splited_element) == 2:\n",
    "                number_list.append(int(re.sub(\",\", \"\", splited_element[1])))\n",
    "            else:\n",
    "                number_list.append(0)\n",
    "\n",
    "        max_number = max(number_list)\n",
    "        click_index = number_list.index(max_number)\n",
    "\n",
    "        # í´ë¦­í•˜ê³  ë Œë”ë§ì´ ì™„ë£Œë˜ë„ë¡ ì¡°ê¸ˆ ê¸°ë‹¤ë¦¬ê¸°\n",
    "        search_list[click_index].click()\n",
    "        time.sleep(2.5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # ì²˜ìŒ ë Œë”ë§ëœ í™”ë©´ì˜ 24ê°œì˜ ê²Œì‹œë¬¼ì„ í¬ë¡¤ë§í•˜ëŠ” í•¨ìˆ˜\n",
    "    def initial_crawling(self):\n",
    "        urls = self.driver.find_elements_by_xpath('//*[@id=\"react-root\"]/section/main/article/div[2]/div/div/div/a')\n",
    "        urls = [url.get_attribute(\"href\") for url in urls]\n",
    "\n",
    "        hash_tag_df = pd.DataFrame(columns=['time', 'hash_tag'])\n",
    "\n",
    "        for i in range(len(urls)):\n",
    "            req = requests.get(urls[i])\n",
    "            response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "            hash_tag_list = response.css(\"meta[property='instapp:hashtags']\")\n",
    "            hash_tag_list = ['#' + hash_tag.attrib['content'] for hash_tag in hash_tag_list]\n",
    "            hash_tags = ', '.join(hash_tag_list)\n",
    "\n",
    "            data = [\n",
    "                {'time': 0, 'hash_tag': hash_tags}\n",
    "            ]\n",
    "            df = pd.DataFrame(data)\n",
    "            hash_tag_df = hash_tag_df.append(df)\n",
    "\n",
    "        return hash_tag_df.reset_index().drop(columns=['index'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # ìŠ¤í¬ë¡¤ë‚´ë¦¬ë©´ì„œ 12ê°œì”© ì¶”ê°€ë˜ëŠ” ê²Œì‹œë¬¼ì„ í¬ë¡¤ë§í•˜ëŠ” í•¨ìˆ˜ (ë‘ë²ˆì§¸ë§Œ ì‹¤í–‰) - chrome ì „ì²´í™”ë©´ ê¸°ì¤€\n",
    "    # í˜„ì¬ ë¸Œë¼ìš°ì € í™”ë©´ í¬ê¸°ì— ë”°ë¼ ì¶”ê°€ì ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ëŠ” div ê°¯ìˆ˜ê°€ ë‹¬ë¼ì§\n",
    "    # ì „ì²´í™”ë©´ ê¸°ì¤€ divì˜ urls ì´ ê°¯ìˆ˜ = 24 -> 36 -> 45 -> 45 -> ...\n",
    "    def second_crawling(self):\n",
    "        \n",
    "        hash_tag_df = pd.DataFrame(columns=['time', 'hash_tag'])\n",
    "        \n",
    "        for i in range(0, 1):\n",
    "            self.driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "            time.sleep(1.5)\n",
    "\n",
    "            urls = self.driver.find_elements_by_xpath('//*[@id=\"react-root\"]/section/main/article/div[2]/div/div/div/a')\n",
    "            urls = [url.get_attribute(\"href\") for url in urls]\n",
    "\n",
    "            for i in range(len(urls) - 12, len(urls)):\n",
    "                req = requests.get(urls[i])\n",
    "                response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "                hash_tag_list = response.css(\"meta[property='instapp:hashtags']\")\n",
    "                hash_tag_list = ['#' + hash_tag.attrib['content'] for hash_tag in hash_tag_list]\n",
    "                hash_tags = ', '.join(hash_tag_list)\n",
    "\n",
    "                data = [\n",
    "                    {'time': 0, 'hash_tag': hash_tags}\n",
    "                ]\n",
    "                df = pd.DataFrame(data)\n",
    "                hash_tag_df = hash_tag_df.append(df)\n",
    "\n",
    "        return hash_tag_df.reset_index().drop(columns=['index'])\n",
    "\n",
    "\n",
    "\n",
    "    # ì„¸ë²ˆì§¸ë¶€í„°ëŠ” ì´ í•¨ìˆ˜ ë°˜ë³µí•˜ê¸° - ê²Œì‹œë¬¼ 9ê°œì”© í¬ë¡¤ë§\n",
    "    def repeat_crawling(self):\n",
    "        \n",
    "        hash_tag_df = pd.DataFrame(columns=['time', 'hash_tag'])\n",
    "        \n",
    "        for i in range(0, 1):\n",
    "            self.driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "            time.sleep(1.5)\n",
    "\n",
    "            urls = self.driver.find_elements_by_xpath('//*[@id=\"react-root\"]/section/main/article/div[2]/div/div/div/a')\n",
    "            urls = [url.get_attribute(\"href\") for url in urls]\n",
    "\n",
    "            for i in range(len(urls) - 9, len(urls)):\n",
    "                req = requests.get(urls[i])\n",
    "                response = TextResponse(req.url, body=req.text, encoding=\"utf-8\")\n",
    "                hash_tag_list = response.css(\"meta[property='instapp:hashtags']\")\n",
    "                hash_tag_list = ['#' + hash_tag.attrib['content'] for hash_tag in hash_tag_list]\n",
    "                hash_tags = ', '.join(hash_tag_list)\n",
    "\n",
    "                data = [\n",
    "                    {'time': 0, 'hash_tag': hash_tags}\n",
    "                ]\n",
    "                df = pd.DataFrame(data)\n",
    "                hash_tag_df = hash_tag_df.append(df)\n",
    "\n",
    "        return hash_tag_df.reset_index().drop(columns=['index'])\n",
    "    \n",
    "\n",
    "    \n",
    "# instagram_crawling í´ë˜ìŠ¤ë¥¼ ì´ìš©í•´ì„œ í•´ì‹œíƒœê·¸ë¥¼ í¬ë¡¤ë§í•˜ê³  ì „ì²´ ë°ì´í„°í”„ë ˆì„ì„ ë¦¬í„´í•œë‹¤\n",
    "def crawling_start(keyword, repeat_num, mongo=0):\n",
    "    \n",
    "    keyword = keyword\n",
    "    num = repeat_num\n",
    "    result_df = pd.DataFrame(columns=['time', 'hash_tag'])\n",
    "    \n",
    "    insta = instagram_crawling()\n",
    "    \n",
    "    insta.login()\n",
    "    insta.crawling_keyword(keyword)\n",
    "    \n",
    "    initial_df = insta.initial_crawling()\n",
    "    result_df = pd.concat([result_df, initial_df])\n",
    "    \n",
    "    second_df = insta.second_crawling()\n",
    "    result_df = pd.concat([result_df, second_df])\n",
    "    \n",
    "    # ë§ˆì§€ë§‰ í¬ë¡¤ë§ í•¨ìˆ˜ ë°˜ë³µ\n",
    "    for i in range(0, num):\n",
    "        try:\n",
    "            df = insta.repeat_crawling()\n",
    "            result_df = pd.concat([result_df, df])\n",
    "        except Exception as exc:\n",
    "            print('ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ : ', exc)\n",
    "    \n",
    "    result_df = result_df.reset_index().drop(columns=['index'])\n",
    "    \n",
    "    \n",
    "    # ì„¸ë²ˆì§¸ ì¸ìë¥¼ 1ë¡œ ë„˜ê²¨ì£¼ë©´, aws mongodbì— ë°ì´í„°ë¥¼ ì €ì¥í•œë‹¤\n",
    "    if mongo == 1:\n",
    "        mongo_df_list = result_df.to_dict(\"records\")\n",
    "        client = pymongo.MongoClient('mongodb://root:dss@13.124.100.70:27017')\n",
    "        db = client.insta_crawling\n",
    "        collection = db.data\n",
    "\n",
    "        for i in range(len(mongo_df_list)):\n",
    "            collection.insert(mongo_df_list[i])\n",
    "    \n",
    "    return result_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idë¥¼ ì…ë ¥í•˜ì„¸ìš”: yeejun90\n",
      "passwordë¥¼ ì…ë ¥í•˜ì„¸ìš”: Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° row ê°¯ìˆ˜ = 24 + 12 + (9 * 2)\n",
    "\n",
    "df = crawling_start('ì´ˆì½”ìš°ìœ ', 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>hash_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>#ì„ íŒ”, #ì´ˆì½”ìš°ìœ , #ì¸ì¹œí™˜ì˜, #ì‹œë¦¬ì–¼, #ëŒ“ê¸€í™˜ì˜, #ë§íŒ”, #ì¼ìƒ, #íŒ”ë¡œìš°...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>#ìƒì¼, #ì´ˆì½”ìš°ìœ , #ë°ì´ì§€, #ğŸ«, #íƒ„ìƒí™”ì»µ, #í™ˆì¹´í˜ë†€ì´, #ìƒì¼ì„ ë¬¼, #í™ˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>#ì–´í”¼ì¹˜ëŠ”, #í–‰ë³µí•˜ë‹¤ê·¸ë¨, #ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹, #ì´ˆì½”ìš°ìœ , #ì‚¬ì£¼ëŠ”, #ì—°ì• í• êº¼ì•¼...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>#gs25, #í­ëŸ½ìœ ì´ˆì½”, #í­ëŸ½ìœ ì´ˆì½”ìš°ìœ , #í­ìˆ˜, #ì´ˆì½”ìš°ìœ </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time                                           hash_tag\n",
       "49    0  #ì„ íŒ”, #ì´ˆì½”ìš°ìœ , #ì¸ì¹œí™˜ì˜, #ì‹œë¦¬ì–¼, #ëŒ“ê¸€í™˜ì˜, #ë§íŒ”, #ì¼ìƒ, #íŒ”ë¡œìš°...\n",
       "50    0                                                   \n",
       "51    0  #ìƒì¼, #ì´ˆì½”ìš°ìœ , #ë°ì´ì§€, #ğŸ«, #íƒ„ìƒí™”ì»µ, #í™ˆì¹´í˜ë†€ì´, #ìƒì¼ì„ ë¬¼, #í™ˆ...\n",
       "52    0  #ì–´í”¼ì¹˜ëŠ”, #í–‰ë³µí•˜ë‹¤ê·¸ë¨, #ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹, #ì´ˆì½”ìš°ìœ , #ì‚¬ì£¼ëŠ”, #ì—°ì• í• êº¼ì•¼...\n",
       "53    0                #gs25, #í­ëŸ½ìœ ì´ˆì½”, #í­ëŸ½ìœ ì´ˆì½”ìš°ìœ , #í­ìˆ˜, #ì´ˆì½”ìš°ìœ "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
